{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704245b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import sqlite3\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "# Access the environment variables\n",
    "project_folder_path = os.getenv('PROJECT_FOLDER_PATH')\n",
    "print(project_folder_path)\n",
    "sys.path.append(project_folder_path)\n",
    "from utils.db_functs import *\n",
    "from utils.requests_functs import *\n",
    "from utils.html_functs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0366616",
   "metadata": {},
   "source": [
    "### Database and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c147be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file_name = 'cev-database-coordinates-v1.db'\n",
    "db_file_path = os.path.join(project_folder_path, 'data', 'sqlite', db_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917318a2",
   "metadata": {},
   "source": [
    "## 1) Define parameters to run a `search`\n",
    "This can be a new search or retake a previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id = '4bd70bab-b20c-4e27-b514-92ff6fa70351'\n",
    "#search_id = '010576e8-90f1-42c4-88bc-3965b5c4c238'\n",
    "search_date = '2024-05-02'\n",
    "#search_date = '2024-04-21'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026074b",
   "metadata": {},
   "source": [
    "## 2) Define a dataframe with download coordinates\n",
    "The dataframe must contain 1 row per `comuna` meaning 348 rows in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840cb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "        SELECT * FROM evals_html_download_coordinates\n",
    "        WHERE search_id = \"{search_id}\";\n",
    "        \"\"\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c740005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe_from_query(db_file_path, query)\n",
    "# Drop specified columns\n",
    "columns_to_drop = ['id']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530862c4",
   "metadata": {},
   "source": [
    "Set additional features to track the status of downloads as well as times and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = None\n",
    "df['html_filename'] = None\n",
    "df['downloaded_at'] = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a20f27",
   "metadata": {},
   "source": [
    "## 3) Check first if any html files has been downloaded\n",
    "This is useful in case a seach has been run and has not completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022334c2",
   "metadata": {},
   "source": [
    "### 3.1) Read all html files for the corresponding `search_date` and `search_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a035e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "html_files_dir = os.path.join(project_folder_path, 'data', 'raw', '2_evals_comuna_page', f'{search_date}_{search_id}', 'html_files')\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(html_files_dir):\n",
    "    # If it doesn't exist, create the directory\n",
    "    os.makedirs(html_files_dir)\n",
    "    print(f\"Directory '{html_files_dir}' created.\")\n",
    "\n",
    "# List all files in the directory\n",
    "html_file_paths = find_html_files(html_files_dir)\n",
    "print(f'The directory: {html_files_dir} contains {len(html_file_paths)} out of {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a107d22",
   "metadata": {},
   "source": [
    "### 3.2) Fill on dataframe all those rows corresponding to files already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b824123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df['combined_key'] = df['region_id'].astype(str) + '_' + df['comuna_id'].astype(str) + '_' + df['tipo_evaluacion'].astype(str) + '_' + df['eventargument'].astype(str)\n",
    "\n",
    "for html_file_path in html_file_paths:\n",
    "    html_file_name = os.path.split(html_file_path)[-1]\n",
    "    html_file_list = html_file_name.split('_')\n",
    "    \n",
    "    region_id = int(html_file_list[0])\n",
    "    comuna_id = int(html_file_list[1])\n",
    "    tipo_evaluacion = int(html_file_list[2])\n",
    "    eventargument = '$'.join(html_file_list[3].split('-')[:2])\n",
    "    number_of_pages = str(html_file_list[3].split('-')[-1])\n",
    "    date = html_file_list[4]\n",
    "    time = html_file_list[5].split('.')[0].replace('-', ':')\n",
    "    date_time = date + ' ' + time\n",
    "    \n",
    "    combined_key = f\"{region_id}_{comuna_id}_{tipo_evaluacion}_{eventargument}\"\n",
    "    \n",
    "    row_index = df.index[df['combined_key'] == combined_key]\n",
    "    if not row_index.empty:\n",
    "        df.loc[row_index, 'status'] = 'Successful'\n",
    "        df.loc[row_index, 'html_filename'] = html_file_name\n",
    "        df.loc[row_index, 'downloaded_at'] = date_time\n",
    "\n",
    "# Drop the combined_key column at the end\n",
    "df.drop(columns=['combined_key'], inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e310332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ac473",
   "metadata": {},
   "source": [
    "### Download html files: 1 file per commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_URL = 'http://calificacionenergeticaweb.minvu.cl/Publico/BusquedaVivienda.aspx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54497447",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ATTEMPTS = 5\n",
    "DELAY_BETWEEN_ATTEMPTS = 15\n",
    "\n",
    "attempts = 0\n",
    "while attempts < MAX_ATTEMPTS:\n",
    "    all_successful = True  # Flag to track if all rows are successful in this attempt\n",
    "    communes_to_process = df[df['status'] != 'Successful'].shape[0]\n",
    "    print(f\"Attempt {attempts + 1} of {MAX_ATTEMPTS}: {communes_to_process} communes to process\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if df.loc[index, 'status'] != 'Successful':\n",
    "            region_id = str(row['region_id'])\n",
    "            commune_id = str(row['comuna_id'])\n",
    "            tipo_evaluacion = str(row['tipo_evaluacion'])\n",
    "            eventtarget = row['eventtarget']\n",
    "            eventargument = row['eventargument']\n",
    "            number_of_pages = str(row['total_pages'])\n",
    "            viewstate = row['viewstate']\n",
    "            form_data = form_data_evaluacion(eventtarget, eventargument, region_id, commune_id, tipo_evaluacion, viewstate)\n",
    "            \n",
    "            print(f\" * Processing {region_id}, {commune_id}\")\n",
    "           \n",
    "            try:\n",
    "                response = requests.post(HOME_URL, data=form_data)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    # Record the current time after making the request\n",
    "                    request_time = datetime.now()\n",
    "                    downloaded_on = request_time.strftime(\"%Y-%m-%d\")\n",
    "                    downloaded_at = request_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    \n",
    "                    df.loc[index, 'status'] = 'Successful'\n",
    "                    \n",
    "                    # Saving html data into a local folder\n",
    "                    html_path = os.path.join(html_files_dir, region_id)\n",
    "                   \n",
    "                    if not os.path.exists(html_path):\n",
    "                        os.makedirs(html_path)\n",
    "                        \n",
    "                    html_filename = region_id + \"_\" + commune_id + \"_\" + tipo_evaluacion + \"_\" + eventargument.split('$')[0] + '-' + eventargument.split('$')[-1] + '-' + str(number_of_pages) + '_' + request_time.strftime(\"%Y-%m-%d_%H-%M-%S\") + '.html'\n",
    "\n",
    "                    \n",
    "\n",
    "                    with open(os.path.join(html_path, html_filename), \"wb\") as f:\n",
    "                        f.write(response.content)                    \n",
    "                    \n",
    "                    df.loc[index, 'html_filename'] = downloaded_at\n",
    "                    df.loc[index, 'downloaded_at'] = downloaded_at\n",
    "                else:\n",
    "                    #df.loc[index, 'status'] = 'Failed'\n",
    "                    print(f\"Request failed for region {region_id}, commune {commune_id}. Skipping to the next row.\")\n",
    "                    continue  # Skip to the next iteration of the loop\n",
    "                #df.loc[index, 'status_code'] = response.status_code\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred for region {region_id}, commune {commune_id}: {str(e)}\")\n",
    "                #df.loc[index, 'status'] = 'Failed'\n",
    "                continue  # Skip to the next iteration of the loop\n",
    "            \n",
    "    \n",
    "    all_successful = all_successful and (df['status'] == 'Successful').all()\n",
    "\n",
    "    if all_successful:\n",
    "        break  # Exit the loop if all rows are successful\n",
    "    else:\n",
    "        attempts += 1\n",
    "        time.sleep(DELAY_BETWEEN_ATTEMPTS)  # Delay between attempts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['eventtarget', 'eventargument', 'viewstate', 'total_evals']\n",
    "out_df = df.drop(columns=columns_to_drop).dropna().reset_index(drop=True)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_unique_rows_from_dataframe(db_file_path, 'evals_html_downloaded_files', out_df, unique_columns=['comuna_id', 'region_id', 'tipo_evaluacion', 'pagina', 'search_id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
