{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704245b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import sqlite3\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "# Access the environment variables\n",
    "project_folder_path = os.getenv('PROJECT_FOLDER_PATH')\n",
    "print(project_folder_path)\n",
    "sys.path.append(project_folder_path)\n",
    "from utils.db_functs import *\n",
    "from utils.requests_functs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08a9ff",
   "metadata": {},
   "source": [
    "### Database and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea50e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file_name = 'cev-database-coordinates-v1.db'\n",
    "db_file_path = os.path.join(project_folder_path, 'data', 'sqlite', db_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb084b1c",
   "metadata": {},
   "source": [
    "## 1) Define parameters to run a `search`\n",
    "This can be a new search or retake a previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1871f",
   "metadata": {},
   "source": [
    "#### 1.1) New search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf83be64-d856-477c-8f8e-f37601fa0a82",
   "metadata": {},
   "source": [
    "\n",
    "search_id = uuid.uuid4()\n",
    "search_date = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d70094",
   "metadata": {},
   "source": [
    "#### 1.2) Previous `search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a1943-f506-46f8-b8a7-ca499c6db053",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id = '4bd70bab-b20c-4e27-b514-92ff6fa70351'\n",
    "#search_id = '010576e8-90f1-42c4-88bc-3965b5c4c238'\n",
    "search_date = '2024-05-02'\n",
    "#search_date = '2024-04-21'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9025cf2",
   "metadata": {},
   "source": [
    "## 2) Define a dataframe with download coordinates\n",
    "The dataframe must contain 1 row per `comuna` meaning 348 rows in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17892519",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT c.comuna_id, c.comuna_name, r.region_id, r.region_name, v.viewstate\n",
    "        FROM comunas AS c\n",
    "        LEFT JOIN regiones AS r ON c.region_id = r.region_id\n",
    "        LEFT JOIN viewstate_region AS v ON r.region_id = v.region_id\n",
    "        ORDER BY r.region_id ASC, c.comuna_id ASC;\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe_from_query(db_file_path, query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdaf47",
   "metadata": {},
   "source": [
    "Set additional features to track the status of downloads as well as times and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['search_id'] = search_id\n",
    "df['search_date'] = search_date\n",
    "df['status'] = None\n",
    "df['html_filename'] = None\n",
    "df['downloaded_at'] = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61155037",
   "metadata": {},
   "source": [
    "## 3) Check first if any html files has been downloaded\n",
    "This is useful in case a seach has been run and has not completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a302f",
   "metadata": {},
   "source": [
    "### 3.1) Read all html files for the corresponding `search_date` and `search_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "html_files_dir = os.path.join(project_folder_path, 'data', 'raw', '1_total_evals_comuna', f'{search_date}_{search_id}', 'html_files')\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(html_files_dir):\n",
    "    # If it doesn't exist, create the directory\n",
    "    os.makedirs(html_files_dir)\n",
    "    print(f\"Directory '{html_files_dir}' created.\")\n",
    "\n",
    "# List all files in the directory\n",
    "html_files = os.listdir(html_files_dir)\n",
    "print(f'The directory: {html_files_dir} contains {len(html_files)} out of {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c3748",
   "metadata": {},
   "source": [
    "### 3.2) Fill on dataframe all those rows corresponding to files already donwloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552eaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df['combined_key'] = df['region_id'].astype(str) + '_' + df['comuna_id'].astype(str)\n",
    "\n",
    "for html_file in html_files:\n",
    "    html_file_list = html_file.split('_')\n",
    "    region_id = int(html_file_list[0])\n",
    "    comuna_id = int(html_file_list[1])\n",
    "    date = html_file_list[2]\n",
    "    time = html_file_list[3].split('.')[0].replace('-', ':')\n",
    "    date_time = date + ' ' + time\n",
    "    #row = df[df['region_id'].astype(str) + '_' + df['comuna_id'].astype(str) == str(region_id) + '_' + str(comuna_id)]\n",
    "    combined_key = f\"{region_id}_{comuna_id}\"    \n",
    "    row_index = df.index[df['combined_key'] == combined_key]\n",
    "\n",
    "    if not row_index.empty:\n",
    "        df.loc[row_index, 'status'] = 'Successful'\n",
    "        df.loc[row_index, 'html_filename'] = html_file\n",
    "        df.loc[row_index, 'downloaded_at'] = date_time\n",
    "    \n",
    "# Drop the combined_key column at the end\n",
    "df.drop(columns=['combined_key'], inplace=True)\n",
    "\n",
    "df.head()\n",
    "#df['status'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ac473",
   "metadata": {},
   "source": [
    "## 3) Download HTML files per Comuna: Only those that have not been downloaded yet\n",
    "For a new run, all files must be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bed82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_URL = 'http://calificacionenergeticaweb.minvu.cl/Publico/BusquedaVivienda.aspx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ATTEMPTS = 5\n",
    "DELAY_BETWEEN_ATTEMPTS = 15\n",
    "\n",
    "attempts = 0\n",
    "while attempts < MAX_ATTEMPTS:\n",
    "    all_successful = True  # Flag to track if all rows are successful in this attempt\n",
    "    communes_to_process = df[df['status'] != 'Successful'].shape[0]\n",
    "    print(f\"Attempt {attempts + 1} of {MAX_ATTEMPTS}: {communes_to_process} communes to process\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if df.loc[index, 'status'] != 'Successful':\n",
    "            region_id = row['region_id']\n",
    "            comuna_id = row['comuna_id']\n",
    "            rating_type = '-1'\n",
    "            viewstate = row['viewstate']\n",
    "            form_data = form_data_consulta(region_id, comuna_id, rating_type, viewstate)\n",
    "            \n",
    "            print(f\" * Processing {row['region_name']}, {row['comuna_name']} / file {index + 1} out of {communes_to_process}\")\n",
    "           \n",
    "            try:\n",
    "                response = requests.post(HOME_URL, data=form_data)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    # Record the current time after making the request\n",
    "                    request_time = datetime.now()\n",
    "                    downloaded_on = request_time.strftime(\"%Y-%m-%d\")\n",
    "                    downloaded_at = request_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    \n",
    "                    df.loc[index, 'status'] = 'Successful'\n",
    "                    \n",
    "                    # Saving html data into a local folder\n",
    "                    html_path = html_files_dir\n",
    "                   \n",
    "                    if not os.path.exists(html_path):\n",
    "                        os.makedirs(html_path)\n",
    "\n",
    "                    html_filename = str(region_id) + \"_\" + str(comuna_id) + \"_\" + request_time.strftime(\"%Y-%m-%d_%H-%M-%S\") + '.html'\n",
    "\n",
    "                    with open(os.path.join(html_path, html_filename), \"wb\") as f:\n",
    "                        f.write(response.content)                    \n",
    "                    \n",
    "                    df.loc[index, 'html_filename'] = html_filename\n",
    "                    df.loc[index, 'downloaded_at'] = downloaded_at\n",
    "                else:\n",
    "                    df.loc[index, 'status'] = 'Failed'\n",
    "                    print(f\"Request failed for region {row['region_name']}, commune {row['comuna_name']}. Skipping to the next row.\")\n",
    "                    continue  # Skip to the next iteration of the loop\n",
    "                #df.loc[index, 'status_code'] = response.status_code\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred for region {row['region_name']}, commune {row['comuna_name']}: {str(e)}\")\n",
    "                df.loc[index, 'status'] = 'Failed'\n",
    "                continue  # Skip to the next iteration of the loop\n",
    "            \n",
    "    \n",
    "    all_successful = all_successful and (df['status'] == 'Successful').all()\n",
    "\n",
    "    if all_successful:\n",
    "        break  # Exit the loop if all rows are successful\n",
    "    else:\n",
    "        attempts += 1\n",
    "        time.sleep(DELAY_BETWEEN_ATTEMPTS)  # Delay between attempts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['region_name', 'comuna_name', 'viewstate']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff4a49",
   "metadata": {},
   "source": [
    "### Save to database\n",
    "Save only those records that are not yet there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_unique_rows_from_dataframe(db_file_path, 'html_files_by_comuna_and_search', df, unique_columns=['comuna_id', 'region_id', 'search_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9aaf76",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
